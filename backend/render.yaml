services:
  - type: web
    name: codex-backend
    env: python
    plan: starter
    region: frankfurt
    rootDir: .
    buildCommand: pip install --upgrade pip && pip install -r backend/requirements.txt
    startCommand: >
      uvicorn backend.app:app
      --host 0.0.0.0 --port $PORT
      --workers 1
      --limit-concurrency 50
      --backlog 64
      --timeout-keep-alive 5
    healthCheckPath: /health
    autoDeploy: true
    envVars:
      - key: OPENAI_API_KEY
        sync: false
      - key: OPENAI_BASE_URL
        value: https://api.fireworks.ai/inference/v1
      - key: OPENAI_MODEL
        value: accounts/fireworks/models/llama-v3p1-70b-instruct

      - key: NEON_URL
        sync: false

      - key: QDRANT_URL
        sync: false
      - key: QDRANT_API_KEY
        sync: false

      - key: EMBED_MODEL
        value: nomic-ai/nomic-embed-text-v1.5
      - key: PRIVATE_COLLECTION
        value: codex-private
      - key: SHARED_COLLECTION
        value: codex-shared

      - key: API_AUTH_TOKEN
        sync: false
